{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/werowe/HypatiaAcademy/blob/master/spark/sparkLR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6bc345c",
      "metadata": {
        "id": "c6bc345c"
      },
      "source": [
        "# Spark ML Example\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "\n",
        "1. [Spark ML Example: Preventive Maintenance](#1)\n",
        "2. [Business Assessment: Use Case Background](#2)\n",
        "3. [Vehicle Fleets and Analytics](#3)\n",
        "4. [Brake Failure Prediction](#4)\n",
        "5. [Brake Pad Maintenance](#5)\n",
        "6. [Ingest data](#6)\n",
        "7. [Prepare data](#7)\n",
        "8. [Train the model](#8)\n",
        "9. [Test the model](#9)\n",
        "10. [Expose the Model as a Web Service](#10)\n",
        "11. [Serve the Model](#11)\n",
        "12. [Complete Code](#12)\n",
        "\n",
        "\n",
        "## <a name=\"1\"></a>Spark ML Example: Preventive Maintenance\n",
        "\n",
        "We take this example from the field of preventive maintenance (PM) as explained below.  Below we discuss the code in depth.  But first we give a use case for why this is needed.\n",
        "\n",
        "\n",
        "## <a name=\"2\"></a>Business Assessment: Use Case Background\n",
        "PM was one of the early adopters of big data analytics and machine learning and IoT (Internet of Things) because it is so simple to conceive and implement for that use case.  Calculating when a machine needs maintenance is a problem that fits neatly into a predictive algorithm. This is because machine wear is a function of time and usage.  \n",
        "\n",
        "\n",
        "## <a name=\"3\"></a>Vehicle Fleets and Analytics\n",
        "IoT-equipped trucks send data from vehicles using a cellular or satellite signal either as a stream or in bursts.  With IoT, trucks are fit with sensors and GPS trackers that measure heat, vibration, distance travelled, speed, etc.  These sensors are attached to the engine, brakes, transmission, refrigerated trailer, etc.\n",
        "\n",
        "\n",
        "Companies gather and study this data to operate their vehicles in the safest and lowest cost manner possible.  For example, sensors on the engine can tell whether the engine has a problem.  It is the goal of PM to fix a device before it breaks as waiting until it breaks is expensive as the engine, brake assembly, or drive train can be destroyed and the vehicle taken out of service for a longer period of time than if it is properly maintained\n",
        "\n",
        "\n",
        "## <a name=\"4\"></a>Brake Failure Prediction\n",
        "A heavy truck with 18 wheels has a unique preventive maintenance problem to solve, and that is knowing when to change brakes.  Trucks needs to know when to replace their brakes so that they do not have an accident or destroy the brake rotor, which is the metal part of the assembly.  If they wait too long the brake pad will destroy the rotor as metal rubs up against metal.   \n",
        "\n",
        "\n",
        "The driver cannot be expected to check every brake every time they stop.  And if the company just changes brakes based on some preset schedule then they are wasting money, because they might be changing them too often. So it is preferred to write some mathematical or statistical model to predict when brakes should be changed.  \n",
        "\n",
        "\n",
        "## <a name=\"5\"></a>Brake Pad Maintenance\n",
        "Brake pads are metal shavings held together by a resin. The brake applies pressure to the pad to force it down on the rotor, which is a metal disk connected to a truck’s axles.  The pad is designed to wear out over time.  It has to be softer than the rotor, so that it does not damage the rotor.   When the brake pad wears down, heat will go up because there is more friction.  And the further a vehicle has been driven the more its brakes will have worn down.\n",
        "\n",
        "\n",
        "We contacted an engineer from Volvo and he verified that this model would work as a teaching exercise as it seems reasonable to correlate heat and distance driven with wear.  To get a more accurate model we would have to use something like data from the [IDA Industrial Challenge](https://ida2016.blogs.dsv.su.se/?page_id=1387), which was a competition made by Scana trucking company.\n",
        "\n",
        "\n",
        "There are lots of factors that impact brake wear.  For example, brakes will wear out faster for vehicles that drive down steep hills.   \n",
        "\n",
        "\n",
        "We do not have any actual sample data.  So we generated some sample date using this rough model:\n",
        "\n",
        "\n",
        "`z = wear_rate = (0.003 * heat) + (0.004 * kilometers)-78`\n",
        "\n",
        "\n",
        "This shows whether the brakes are worn out given the kilometers driven and the maximum heat generated during gathering the sample.\n",
        "\n",
        "\n",
        "We plug that value into the logistic probability function:\n",
        "\n",
        "\n",
        "`pr = 1 / (1 + e**-z)`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The binary logistic model generates a binary output, which we will call worn. So if pr > 50% then worn = 1. Otherwise worn = 0. If worn = 1 then it is time to change brake pads.\n",
        "\n",
        "\n",
        "\n",
        "## <a name=\"6\"></a>Ingest Data\n",
        "  \n",
        "\n",
        "\n",
        "The sample data is [here](https://raw.githubusercontent.com/werowe/mist_preventive_maintenance_ml/master/brakedata.csv).  Below is the first line.\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td>worn</td><td>km</td><td>heat</td><td>z</td><td>pr</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>1</td><td>20,000</td><td>240</td><td>2.72</td><td>0.938197</td>\n",
        "</tr>\n",
        "\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/werowe/mist_preventive_maintenance_ml/master/brakedata.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sznrfjI9NqgY",
        "outputId": "1eea2f5f-b26b-4f39-ace7-5dbe7bde4811"
      },
      "id": "sznrfjI9NqgY",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-26 09:28:51--  https://raw.githubusercontent.com/werowe/mist_preventive_maintenance_ml/master/brakedata.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 397 [text/plain]\n",
            "Saving to: ‘brakedata.csv.2’\n",
            "\n",
            "\rbrakedata.csv.2       0%[                    ]       0  --.-KB/s               \rbrakedata.csv.2     100%[===================>]     397  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-26 09:28:51 (7.45 MB/s) - ‘brakedata.csv.2’ saved [397/397]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "db43c6f9",
      "metadata": {
        "id": "db43c6f9"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"predict-brakes\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We read this data into a Spark data frame and then select only the first three columns: whether the brake is worn, kilometers, brake rotor heat.\n",
        "\n"
      ],
      "metadata": {
        "id": "qpbqVcJPSj6R"
      },
      "id": "qpbqVcJPSj6R"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a9eefda8",
      "metadata": {
        "id": "a9eefda8"
      },
      "outputs": [],
      "source": [
        "# brake train\n",
        "\n",
        "import pandas as pd\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
        "\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "df = spark.read.csv(\n",
        "    \"brakedata.csv\",\n",
        "    header=True,        # Use the first row as column names\n",
        "    inferSchema=True,   # Automatically infer data types\n",
        "    sep=\",\",            # Specify delimiter (default is ',')\n",
        "    encoding=\"UTF-8\"    # Handle encoding\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look the data:"
      ],
      "metadata": {
        "id": "oxd6LNhoSnyP"
      },
      "id": "oxd6LNhoSnyP"
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFQyb43GOZz4",
        "outputId": "fa56afb1-383a-4194-d91d-f85d87ce70dd"
      },
      "id": "VFQyb43GOZz4",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+----+-------+--------+\n",
            "|worn|    km|heat|      z|      pr|\n",
            "+----+------+----+-------+--------+\n",
            "|   1|20,000| 240|   2.72|0.938197|\n",
            "|   0| 5,000|  98|-57.706|     0.0|\n",
            "|   1|50,000| 140| 122.42|     1.0|\n",
            "|   0| 8,000| 260| -45.22|     0.0|\n",
            "|   1|23,790| 225| 17.835|     1.0|\n",
            "|   1|24,644| 245| 21.311|     1.0|\n",
            "|   1|29,934| 195| 42.321|     1.0|\n",
            "|   0|14,045| 153|-21.361|     0.0|\n",
            "|   0| 8,000| 222|-45.334|     0.0|\n",
            "|   0| 9,855| 149|-38.133|     0.0|\n",
            "|   1|24,633| 271| 21.345|     1.0|\n",
            "|   1|20,753| 209|  5.639|0.996456|\n",
            "+----+------+----+-------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name=\"7\"></a>Prepare Data\n",
        "The Spark ML LogisticRegressionWithLBFGS algorithm requires that we put the data into an iterable object of Labels and Points.  So we have an array of LabeledPoint objects.  The Label is the result of logistic regression.  In this case it indicates whether the brake is worn (1) or not (0).  The Points are the kilometers (km) and temperature (heat)."
      ],
      "metadata": {
        "id": "7VlARTKHS0oE"
      },
      "id": "7VlARTKHS0oE"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace, col\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "\n",
        "a = []\n",
        "\n",
        "cols = [\"worn\", \"km\", \"heat\"]\n",
        "\n",
        "for c in cols:\n",
        "  df = df.withColumn(c, regexp_replace(col(c), \",\", \"\").cast(IntegerType()))\n",
        "\n",
        "\n",
        "def parsePoint(w,k,h):\n",
        "    return LabeledPoint(worn, [km, heat])\n",
        "\n",
        "\n",
        "for row in df.collect():\n",
        "\n",
        "    worn = row[\"worn\"]\n",
        "    km = row[\"km\"]\n",
        "    heat = row[\"heat\"]\n",
        "\n",
        "    lp = parsePoint (worn, km, heat)\n",
        "\n",
        "    a.append(lp)"
      ],
      "metadata": {
        "id": "yayOmY27OHbH"
      },
      "id": "yayOmY27OHbH",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name=\"8\"></a>Train the Model\n",
        "Now we train the model by passing that array into LogisticRegressionWithLBFGS.train.  \n",
        "\n",
        "Once the model lrm is created, we can call the lrm.predict() method."
      ],
      "metadata": {
        "id": "NzuHAonvR-81"
      },
      "id": "NzuHAonvR-81"
    },
    {
      "cell_type": "code",
      "source": [
        "lrm = LogisticRegressionWithLBFGS.train(sc.parallelize(a))"
      ],
      "metadata": {
        "id": "a80oDTOxR9Tp"
      },
      "id": "a80oDTOxR9Tp",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <a name=\"9\"></a>Test the Model\n",
        "To test the model we take the training data and then run the prediction over each data point in the sample data.  We then count how many correct predictions there are and divide that by the sample size.  That calculates the model accuracy."
      ],
      "metadata": {
        "id": "MmtivlW1Ruv4"
      },
      "id": "MmtivlW1Ruv4"
    },
    {
      "cell_type": "code",
      "source": [
        "p = sc.parallelize(a)\n",
        "\n",
        "valuesAndPreds = p.map(lambda p: (p.label, lrm.predict(p.features)))\n",
        "\n",
        "\n",
        "accurate = 1 - valuesAndPreds.map(lambda vp: math.fabs(vp[0] - vp[1])).reduce(lambda x, y: x + y) / valuesAndPreds.count()"
      ],
      "metadata": {
        "id": "NWXR0aYISDHZ"
      },
      "id": "NWXR0aYISDHZ",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here get a random row and then use `collect()[0]` to return it as a list and take the first item, and only item in the list.\n",
        "\n",
        "The run the prediction."
      ],
      "metadata": {
        "id": "HV0UYDBJV-a4"
      },
      "id": "HV0UYDBJV-a4"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "4729bfff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4729bfff",
        "outputId": "d823b6ed-b385-4f6a-c7eb-3972ab64dbf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(worn=1, km=23790, heat=225, z=17.835, pr=1.0, random=0.00015032723787544722) \n",
            "\n",
            "heat 225 km 23790\n",
            "\n",
            "brake is worn= 1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import re\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import rand\n",
        "\n",
        "random_row = df.withColumn(\"random\", rand()).orderBy(\"random\").limit(1).collect()[0]\n",
        "\n",
        "print(random_row , \"\\n\")\n",
        "\n",
        "km = random_row['km']\n",
        "heat = random_row['heat']\n",
        "\n",
        "\n",
        "\n",
        "print(\"heat %i km %i\" % ( heat,km))\n",
        "\n",
        "\n",
        "worn = lrm.predict([km,heat])\n",
        "print(\"\\nbrake is worn=\", worn)\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}