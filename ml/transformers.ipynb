{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPL+6EMu/cRp71o4R3xvq4U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/werowe/HypatiaAcademy/blob/master/ml/transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "From video https://www.youtube.com/watch?v=QEaBAZQCtwE\n",
        "\n",
        "\n",
        "* how to use the pipeline how to use model\n",
        "\n",
        "* and tokenizer how to combine it with\n",
        "\n",
        "* pytorch or tensorflow how to save and\n",
        "\n",
        "* load models how to use models from the\n",
        "\n",
        "* official model hub and also how to fine\n",
        "\n",
        "* tune your own models\n",
        "\n",
        "\n",
        "works with tensorflow, pytorch, or flex\n"
      ],
      "metadata": {
        "id": "G9IKJ4xoBRno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "res = classifier(\"It's so hot today in Cyprus\")\n",
        "\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "OcFADEymvAez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ceea260-9e59-4d73-ba67-986c52ae76be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9993522763252258}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  apply tokenizer\n",
        "2.  feed preprocessed text to the model and applies model\n",
        "3.  post processor\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wMg0a08xAP3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation Pipeline"
      ],
      "metadata": {
        "id": "mq_U_QPvCCfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "res = generator(\n",
        "    \"Today we will learn about transformers\",\n",
        "    max_length=50,\n",
        "    num_return_sequences=2\n",
        "\n",
        ")\n",
        "\n",
        "for dis in res:\n",
        "  print(dis.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soAIWojKBrTR",
        "outputId": "27798082-3be3-403c-b08f-b8d3d49ba30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values(['Today we will learn about transformers using techniques to achieve good results to optimize optimization. The following resources will be provided to you:'])\n",
            "dict_values(['Today we will learn about transformers and their technology.\\n\\n\\n\\nOur future is more than the invention of technology. As the field changes we need a revolution to see if changes can be turned into practical solutions to a problem, we want to'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "res = generator(\n",
        "    \"Cyprus is a boring place\",\n",
        "    candidate_labels=[\"criticism\", \"education\", \"business\"]\n",
        "\n",
        ")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(res['scores'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdVq9zVlDflT",
        "outputId": "a4e04110-8bab-43ba-93fc-434d0973872d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[0.9652251601219177, 0.028426004573702812, 0.006348819006234407]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "classification this means we can give it\n",
        "\n",
        "a text without knowing the corresponding\n",
        "\n",
        "label .  It then looks at the labels and sees which matches by percentage the text."
      ],
      "metadata": {
        "id": "8t1YVB9fD5_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "kS0J-0DhFFyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertModel\n",
        "\n",
        "\n",
        "\n",
        "model_name=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "text=\"It's so hot today in Cyprus.\"\n",
        "\n",
        "res = classifier(text)\n",
        "\n",
        "print(res)\n",
        "\n",
        "\n",
        "\n",
        "res=tokenizer(text)\n",
        "print(\"\\n res=\", res)\n",
        "\n",
        "tokens=tokenizer.tokenize(text)\n",
        "print(\"\\n tokens=\", tokens)\n",
        "\n",
        "ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(\"\\n ids=\", ids)\n",
        "\n",
        "decoded_string=tokenizer.decode(ids)\n",
        "print(\"\\n decoded_string=\",decoded_string)\n",
        "\n",
        "\n",
        "# 101 is begin sentence\n",
        "# 102 is end sentence\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNvihKenFHzD",
        "outputId": "b3740d1d-ed16-4cc0-8890-b5cd2116b50b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9993836879730225}]\n",
            "\n",
            " res= {'input_ids': [101, 2009, 1005, 1055, 2061, 2980, 2651, 1999, 9719, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            " tokens= ['it', \"'\", 's', 'so', 'hot', 'today', 'in', 'cyprus', '.']\n",
            "\n",
            " ids= [2009, 1005, 1055, 2061, 2980, 2651, 1999, 9719, 1012]\n",
            "\n",
            " decoded_string= it's so hot today in cyprus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# https://huggingface.co/ukr-models/xlm-roberta-base-uk\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ukr-models/xlm-roberta-base-uk\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"ukr-models/xlm-roberta-base-uk\")\n",
        "\n",
        "\n",
        "unmasker = pipeline('fill-mask', model='ukr-models/xlm-roberta-base-uk')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "text = \"\"\"\n",
        "Ми знову запрошуємо підлітків  <mask> з України віком від 13 до 19 років на БЕЗКОШТОВНИЙ курс  у американського успішного викладача- програміста з програмування на Python. Python - це ТОП1 мова у світі програмування.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "res=tokenizer(text)\n",
        "print(\"\\n res=\", res)\n",
        "\n",
        "tokens=tokenizer.tokenize(text)\n",
        "print(\"\\n tokens=\", tokens)\n",
        "\n",
        "ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(\"\\n ids=\", ids)\n",
        "\n",
        "decoded_string=tokenizer.decode(ids)\n",
        "print(\"\\n decoded_string=\",decoded_string, \"\\n\\n\")\n",
        "\n",
        "unmasker(text)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8PSgZcVLbTV",
        "outputId": "fb386bec-35b5-49b0-e9d6-7146fc40bc7b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " res= {'input_ids': [0, 2688, 17222, 30223, 1228, 1618, 7749, 4234, 6, 31273, 210, 1702, 14213, 419, 1096, 702, 255, 953, 4664, 29, 24807, 7799, 2693, 28254, 14377, 4943, 84, 25902, 1041, 28385, 695, 18650, 15912, 9, 5725, 20730, 210, 5725, 2741, 29, 24420, 5, 24420, 20, 1544, 25947, 418, 8355, 84, 14042, 5725, 2741, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            " tokens= ['▁Ми', '▁знову', '▁запрошує', 'мо', '▁під', 'літ', 'ків', '▁', '<mask>', '▁з', '▁України', '▁вік', 'ом', '▁від', '▁13', '▁до', '▁19', '▁років', '▁на', '▁БЕЗ', 'КО', 'Ш', 'ТОВ', 'НИЙ', '▁курс', '▁у', '▁американськ', 'ого', '▁успішно', 'го', '▁виклад', 'ача', '-', '▁програм', 'іста', '▁з', '▁програм', 'ування', '▁на', '▁Python', '.', '▁Python', '▁-', '▁це', '▁ТОП', '1', '▁мова', '▁у', '▁світі', '▁програм', 'ування', '.']\n",
            "\n",
            " ids= [2688, 17222, 30223, 1228, 1618, 7749, 4234, 6, 31273, 210, 1702, 14213, 419, 1096, 702, 255, 953, 4664, 29, 24807, 7799, 2693, 28254, 14377, 4943, 84, 25902, 1041, 28385, 695, 18650, 15912, 9, 5725, 20730, 210, 5725, 2741, 29, 24420, 5, 24420, 20, 1544, 25947, 418, 8355, 84, 14042, 5725, 2741, 5]\n",
            "\n",
            " decoded_string= Ми знову запрошуємо підлітків <mask> з України віком від 13 до 19 років на БЕЗКОШТОВНИЙ курс у американського успішного викладача- програміста з програмування на Python. Python - це ТОП1 мова у світі програмування. \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.5255579352378845,\n",
              "  'token': 23347,\n",
              "  'token_str': 'ІТ',\n",
              "  'sequence': 'Ми знову запрошуємо підлітків ІТ з України віком від 13 до 19 років на БЕЗКОШТОВНИЙ курс у американського успішного викладача- програміста з програмування на Python. Python - це ТОП1 мова у світі програмування.'},\n",
              " {'score': 0.13842427730560303,\n",
              "  'token': 29189,\n",
              "  'token_str': 'службовців',\n",
              "  'sequence': 'Ми знову запрошуємо підлітків службовців з України віком від 13 до 19 років на БЕЗКОШТОВНИЙ курс у американського успішного викладача- програміста з програмування на Python. Python - це ТОП1 мова у світі програмування.'},\n",
              " {'score': 0.059892717748880386,\n",
              "  'token': 4,\n",
              "  'token_str': ',',\n",
              "  'sequence': 'Ми знову запрошуємо підлітків, з України віком від 13 до 19 років на БЕЗКОШТОВНИЙ курс у американського успішного викладача- програміста з програмування на Python. Python - це ТОП1 мова у світі програмування.'},\n",
              " {'score': 0.04573393613100052,\n",
              "  'token': 23348,\n",
              "  'token_str': 'спеціаліст',\n",
              "  'sequence': 'Ми знову запрошуємо підлітків спеціаліст з України віком від 13 до 19 років на БЕЗКОШТОВНИЙ курс у американського успішного викладача- програміста з програмування на Python. Python - це ТОП1 мова у світі програмування.'},\n",
              " {'score': 0.03969251736998558,\n",
              "  'token': 18302,\n",
              "  'token_str': 'STEM',\n",
              "  'sequence': 'Ми знову запрошуємо підлітків STEM з України віком від 13 до 19 років на БЕЗКОШТОВНИЙ курс у американського успішного викладача- програміста з програмування на Python. Python - це ТОП1 мова у світі програмування.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Recognition\n"
      ],
      "metadata": {
        "id": "OsAH_FvPJKFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "captioner = pipeline(model=\"ydshieh/vit-gpt2-coco-en\")\n",
        "captioner(\"https://th.bing.com/th/id/OIP.SBYtWe52Cb3ecG65Z0ae8wAAAA?rs=1&pid=ImgDetMain\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21eiKLIWJOG9",
        "outputId": "a3bd99d8-288d-48f3-af84-aee8242c02f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'a large boat with a large cargo ship on it '}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}