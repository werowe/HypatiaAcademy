{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/werowe/HypatiaAcademy/blob/master/stats/consolidate_weather_data_run_sql_spark_queries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "66d4c911-ce31-48b6-8481-cfb6c16a8d7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66d4c911-ce31-48b6-8481-cfb6c16a8d7f",
        "outputId": "980f4205-ef42-4989-d378-1d79ab3e4782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "93195920-9c74-4605-a6ba-b5c3b67f41af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93195920-9c74-4605-a6ba-b5c3b67f41af",
        "outputId": "490e2866-5d9e-4437-c29c-9faeb3a18cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined DataFrame shape: (11200, 24)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the directory containing the CSV files\n",
        "directory = 'drive/MyDrive/weather'\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Loop through files in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    # Check if the file starts with 'paphos2024' and ends with '.csv'\n",
        "    if filename.startswith('paphos20') and filename.endswith('.csv'):\n",
        "        # Read the CSV file into a DataFrame\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        df = pd.read_csv(filepath)\n",
        "        dataframes.append(df)\n",
        "\n",
        "# Combine all DataFrames into one\n",
        "df_combined = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Drop duplicate rows\n",
        "df_combined = df_combined.drop_duplicates()\n",
        "\n",
        "# Save the combined DataFrame to a new CSV file (optional)\n",
        "df_combined.to_csv('combined_weather.csv', index=False)\n",
        "\n",
        "# Print a summary of the combined DataFrame\n",
        "print(f\"Combined DataFrame shape: {df_combined.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d274ac16-319c-452b-908f-1e4d16615dff",
      "metadata": {
        "id": "d274ac16-319c-452b-908f-1e4d16615dff"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"weather\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\n",
        "    \"combined_weather.csv\",\n",
        "    header=True,        # Use the first row as column names\n",
        "    inferSchema=True,   # Automatically infer data types\n",
        "    sep=\",\",            # Specify delimiter (default is ',')\n",
        "    encoding=\"UTF-8\"    # Handle encoding\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "IupJCWCHKOsi",
        "outputId": "69328f0a-09d6-433d-b659-d240870c515e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IupJCWCHKOsi",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['name',\n",
              " 'datetime',\n",
              " 'temp',\n",
              " 'feelslike',\n",
              " 'dew',\n",
              " 'humidity',\n",
              " 'precip',\n",
              " 'precipprob',\n",
              " 'preciptype',\n",
              " 'snow',\n",
              " 'snowdepth',\n",
              " 'windgust',\n",
              " 'windspeed',\n",
              " 'winddir',\n",
              " 'sealevelpressure',\n",
              " 'cloudcover',\n",
              " 'visibility',\n",
              " 'solarradiation',\n",
              " 'solarenergy',\n",
              " 'uvindex',\n",
              " 'severerisk',\n",
              " 'conditions',\n",
              " 'icon',\n",
              " 'stations']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"weather\")"
      ],
      "metadata": {
        "id": "8SUAdh7AKQv7"
      },
      "id": "8SUAdh7AKQv7",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sql = '''\n",
        "SELECT SUM(precip) AS total_precip, YEAR(datetime) AS year, MONTH(datetime) AS month\n",
        "FROM weather\n",
        "GROUP BY YEAR(datetime), MONTH(datetime)\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dXKQSRLKVhe",
        "outputId": "1045eb1e-4b02-4077-80ae-c6fbadd598c7"
      },
      "id": "8dXKQSRLKVhe",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----+-----+\n",
            "|      total_precip|year|month|\n",
            "+------------------+----+-----+\n",
            "|               0.0|2024|    7|\n",
            "|486.78400000000016|2024|   12|\n",
            "|1.6430000000000005|2024|    9|\n",
            "|1.5000000000000002|2024|   10|\n",
            "|            23.965|2024|    1|\n",
            "|166.32799999999978|2024|   11|\n",
            "| 7.687999999999999|2025|    1|\n",
            "|             0.008|2024|    8|\n",
            "+------------------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT round(avg(temp),2) AS temp, YEAR(datetime) AS year, MONTH(datetime) AS month\n",
        "FROM weather\n",
        "GROUP BY YEAR(datetime), MONTH(datetime)\n",
        "sort by month\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "J-BfRSsAtLLi",
        "outputId": "e2357f98-08e0-4c3e-bc1f-23b9376a0a63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J-BfRSsAtLLi",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+-----+\n",
            "| temp|year|month|\n",
            "+-----+----+-----+\n",
            "|15.28|2024|    1|\n",
            "|14.41|2025|    1|\n",
            "|29.12|2024|    7|\n",
            "|28.42|2024|    8|\n",
            "|26.56|2024|    9|\n",
            "|22.68|2024|   10|\n",
            "|18.29|2024|   11|\n",
            "|15.07|2024|   12|\n",
            "+-----+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT avg(temp) AS temp, YEAR(datetime) AS year\n",
        "FROM weather\n",
        "GROUP BY YEAR(datetime)\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "bJKTvVCMtt0k",
        "outputId": "70cff07b-f018-459d-8280-8bc229572a50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bJKTvVCMtt0k",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----+\n",
            "|              temp|year|\n",
            "+------------------+----+\n",
            "|14.406673209028435|2025|\n",
            "|22.018947058245622|2024|\n",
            "+------------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT YEAR(datetime) AS year, MONTH(datetime) AS month, AVG(temp) AS avg_temp\n",
        "FROM weather\n",
        "WHERE YEAR(datetime) IN (2025, 2024) AND MONTH(datetime) = 1\n",
        "GROUP BY YEAR(datetime), MONTH(datetime);\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "UBWbrQiJuYOX",
        "outputId": "791fbb61-e8ae-4b87-bdaf-3e36fba86278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UBWbrQiJuYOX",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+------------------+\n",
            "|year|month|          avg_temp|\n",
            "+----+-----+------------------+\n",
            "|2024|    1|15.282291666666676|\n",
            "|2025|    1|14.406673209028435|\n",
            "+----+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# skip sea as runs slow\n",
        "\n",
        "seago=True\n",
        "\n",
        "if seago==False:\n",
        "  exit()\n"
      ],
      "metadata": {
        "id": "D2nBVAg2M1oL"
      },
      "id": "D2nBVAg2M1oL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sea"
      ],
      "metadata": {
        "id": "IbdsQCKaFl7n"
      },
      "id": "IbdsQCKaFl7n"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "ga=[]\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "       if filename.endswith('waves.json'):\n",
        "        # Read the CSV file into a DataFrame\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        fo = open(filepath)\n",
        "        fs=fo.read()\n",
        "        jf=json.loads(fs)\n",
        "        for s in jf['hours']:\n",
        "          f=[s['time'], s['waterTemperature']['noaa'],s['waveHeight']['noaa'],s['swellHeight']['noaa'],s['windWaveHeight']['noaa']]\n",
        "          g=pd.DataFrame(f).T\n",
        "          g.columns=['time','temp','height', 'swell', 'wind']\n",
        "          g['time'] = pd.to_datetime(g['time'])\n",
        "          g.set_index(\"time\", inplace=True)\n",
        "          ga.append(g)\n",
        "        fo.close()\n",
        "\n",
        "\n",
        "\n",
        "# Combine all DataFrames into one\n",
        "sdf = pd.concat(ga, ignore_index=False)\n",
        "\n",
        "# Drop duplicate rows\n",
        "sdfc = sdf.drop_duplicates()\n",
        "\n"
      ],
      "metadata": {
        "id": "eHe-M5ycFnqJ"
      },
      "id": "eHe-M5ycFnqJ",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdfc = sdfc.reset_index()\n",
        "\n",
        "spark_df = spark.createDataFrame(sdfc)"
      ],
      "metadata": {
        "id": "BXQUPgQIKiKj"
      },
      "id": "BXQUPgQIKiKj",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.createOrReplaceTempView(\"sea\")"
      ],
      "metadata": {
        "id": "-qJ_BlzsKix4"
      },
      "id": "-qJ_BlzsKix4",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT\n",
        "    round(MAX(height),2) AS max_height,\n",
        "    round(AVG(height),2) AS avg_height,\n",
        "    YEAR(time) AS year,\n",
        "    MONTH(time) AS month\n",
        "FROM sea\n",
        "WHERE HOUR(time) = 12\n",
        "GROUP BY YEAR(time), MONTH(time)\n",
        "ORDER BY avg_height desc\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "xpcEGPAsKcKF",
        "outputId": "bdec881e-1330-46fb-8ba4-f6cf64a24c74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xpcEGPAsKcKF",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+----+-----+\n",
            "|max_height|avg_height|year|month|\n",
            "+----------+----------+----+-----+\n",
            "|      2.61|      1.26|2024|    1|\n",
            "|      4.26|      0.97|2023|   11|\n",
            "|      2.45|      0.95|2024|   12|\n",
            "|      1.25|      0.87|2024|    7|\n",
            "|      2.02|      0.85|2024|    9|\n",
            "|      1.14|      0.82|2023|    7|\n",
            "|      1.28|      0.81|2023|    8|\n",
            "|      2.46|      0.79|2023|   12|\n",
            "|      3.14|      0.78|2024|   11|\n",
            "|      1.25|      0.72|2024|    8|\n",
            "|      1.16|      0.62|2023|    9|\n",
            "|      1.69|      0.56|2023|   10|\n",
            "|      2.07|      0.53|2024|   10|\n",
            "|      1.04|      0.52|2025|    1|\n",
            "+----------+----------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT * from sea\n",
        "order by YEAR(time) desc, MONTH(time) desc\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "RYTjdxiYIWkY",
        "outputId": "237e9683-be83-45e3-f478-81f597b7effa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RYTjdxiYIWkY",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+------+-----+----+\n",
            "|               time| temp|height|swell|wind|\n",
            "+-------------------+-----+------+-----+----+\n",
            "|2025-01-01 00:00:00|19.14|  0.83| 0.76|0.27|\n",
            "|2025-01-01 20:00:00|19.18|  0.42| 0.42|0.34|\n",
            "|2025-01-01 01:00:00|19.17|  0.81| 0.74|0.24|\n",
            "|2025-01-01 02:00:00| 19.2|  0.78| 0.73|0.21|\n",
            "|2025-01-01 03:00:00|19.23|  0.76| 0.71|0.18|\n",
            "|2025-01-01 04:00:00|19.22|  0.73| 0.51|0.16|\n",
            "|2025-01-01 05:00:00| 19.2|  0.69| 0.31|0.15|\n",
            "|2025-01-01 06:00:00|19.19|  0.66| 0.11|0.13|\n",
            "|2025-01-01 07:00:00|19.19|  0.63| 0.26|0.12|\n",
            "|2025-01-01 08:00:00|19.19|  0.61| 0.41|0.11|\n",
            "|2025-01-01 09:00:00|19.19|  0.58| 0.56| 0.1|\n",
            "|2025-01-01 10:00:00|19.22|  0.56| 0.54|0.27|\n",
            "|2025-01-01 11:00:00|19.24|  0.53| 0.52|0.45|\n",
            "|2025-01-01 12:00:00|19.27|  0.51|  0.5|0.62|\n",
            "|2025-01-01 13:00:00|19.23|   0.5| 0.49|0.59|\n",
            "|2025-01-01 14:00:00| 19.2|  0.49| 0.48|0.56|\n",
            "|2025-01-01 15:00:00|19.16|  0.48| 0.47|0.53|\n",
            "|2025-01-01 16:00:00|19.18|  0.47| 0.46|0.48|\n",
            "|2025-01-01 17:00:00| 19.2|  0.46| 0.45|0.42|\n",
            "|2025-01-01 18:00:00|19.21|  0.45| 0.44|0.37|\n",
            "+-------------------+-----+------+-----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}