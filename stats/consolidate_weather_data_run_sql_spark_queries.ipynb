{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/werowe/HypatiaAcademy/blob/master/stats/consolidate_weather_data_run_sql_spark_queries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "66d4c911-ce31-48b6-8481-cfb6c16a8d7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66d4c911-ce31-48b6-8481-cfb6c16a8d7f",
        "outputId": "f2278315-e8dd-4745-bba3-cecb3249852d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "93195920-9c74-4605-a6ba-b5c3b67f41af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93195920-9c74-4605-a6ba-b5c3b67f41af",
        "outputId": "909e28ce-a9f9-4448-ddb2-e7a21062b562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined DataFrame shape: (11200, 24)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the directory containing the CSV files\n",
        "directory = 'drive/MyDrive/weather'\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Loop through files in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    # Check if the file starts with 'paphos2024' and ends with '.csv'\n",
        "    if filename.startswith('paphos20') and filename.endswith('.csv'):\n",
        "        # Read the CSV file into a DataFrame\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        df = pd.read_csv(filepath)\n",
        "        dataframes.append(df)\n",
        "\n",
        "# Combine all DataFrames into one\n",
        "df_combined = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Drop duplicate rows\n",
        "df_combined = df_combined.drop_duplicates()\n",
        "\n",
        "# Save the combined DataFrame to a new CSV file (optional)\n",
        "df_combined.to_csv('combined_weather.csv', index=False)\n",
        "\n",
        "# Print a summary of the combined DataFrame\n",
        "print(f\"Combined DataFrame shape: {df_combined.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d274ac16-319c-452b-908f-1e4d16615dff",
      "metadata": {
        "id": "d274ac16-319c-452b-908f-1e4d16615dff"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"weather\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\n",
        "    \"combined_weather.csv\",\n",
        "    header=True,        # Use the first row as column names\n",
        "    inferSchema=True,   # Automatically infer data types\n",
        "    sep=\",\",            # Specify delimiter (default is ',')\n",
        "    encoding=\"UTF-8\"    # Handle encoding\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "IupJCWCHKOsi",
        "outputId": "74d5d9b8-ead1-4e26-daee-aee562bc9ccc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IupJCWCHKOsi",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['name',\n",
              " 'datetime',\n",
              " 'temp',\n",
              " 'feelslike',\n",
              " 'dew',\n",
              " 'humidity',\n",
              " 'precip',\n",
              " 'precipprob',\n",
              " 'preciptype',\n",
              " 'snow',\n",
              " 'snowdepth',\n",
              " 'windgust',\n",
              " 'windspeed',\n",
              " 'winddir',\n",
              " 'sealevelpressure',\n",
              " 'cloudcover',\n",
              " 'visibility',\n",
              " 'solarradiation',\n",
              " 'solarenergy',\n",
              " 'uvindex',\n",
              " 'severerisk',\n",
              " 'conditions',\n",
              " 'icon',\n",
              " 'stations']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"weather\")"
      ],
      "metadata": {
        "id": "8SUAdh7AKQv7"
      },
      "id": "8SUAdh7AKQv7",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sql = '''\n",
        "SELECT SUM(precip) AS total_precip, YEAR(datetime) AS year, MONTH(datetime) AS month\n",
        "FROM weather\n",
        "GROUP BY YEAR(datetime), MONTH(datetime)\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dXKQSRLKVhe",
        "outputId": "033e9773-fc0f-47c0-eeaa-fc590d60f071"
      },
      "id": "8dXKQSRLKVhe",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----+-----+\n",
            "|      total_precip|year|month|\n",
            "+------------------+----+-----+\n",
            "|               0.0|2024|    7|\n",
            "|486.78400000000016|2024|   12|\n",
            "|1.6430000000000005|2024|    9|\n",
            "|1.5000000000000002|2024|   10|\n",
            "|            23.965|2024|    1|\n",
            "|166.32799999999978|2024|   11|\n",
            "| 7.687999999999999|2025|    1|\n",
            "|             0.008|2024|    8|\n",
            "+------------------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT round(avg(temp),2) AS temp, YEAR(datetime) AS year, MONTH(datetime) AS month\n",
        "FROM weather\n",
        "GROUP BY YEAR(datetime), MONTH(datetime)\n",
        "sort by month\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "J-BfRSsAtLLi",
        "outputId": "34b692aa-023c-480e-be37-58851cd34ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J-BfRSsAtLLi",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+-----+\n",
            "| temp|year|month|\n",
            "+-----+----+-----+\n",
            "|15.28|2024|    1|\n",
            "|14.41|2025|    1|\n",
            "|29.12|2024|    7|\n",
            "|28.42|2024|    8|\n",
            "|26.56|2024|    9|\n",
            "|22.68|2024|   10|\n",
            "|18.29|2024|   11|\n",
            "|15.07|2024|   12|\n",
            "+-----+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT avg(temp) AS temp, YEAR(datetime) AS year\n",
        "FROM weather\n",
        "GROUP BY YEAR(datetime)\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "bJKTvVCMtt0k",
        "outputId": "f6cc90b0-edb0-4f79-ac6f-0969c350e18e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bJKTvVCMtt0k",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----+\n",
            "|              temp|year|\n",
            "+------------------+----+\n",
            "|14.406673209028435|2025|\n",
            "|22.018947058245622|2024|\n",
            "+------------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT YEAR(datetime) AS year, MONTH(datetime) AS month, AVG(temp) AS avg_temp\n",
        "FROM weather\n",
        "WHERE YEAR(datetime) IN (2025, 2024) AND MONTH(datetime) = 1\n",
        "GROUP BY YEAR(datetime), MONTH(datetime);\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "UBWbrQiJuYOX",
        "outputId": "2c4a3803-6a2c-4703-fd8f-816e1e4cf64a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UBWbrQiJuYOX",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+------------------+\n",
            "|year|month|          avg_temp|\n",
            "+----+-----+------------------+\n",
            "|2024|    1|15.282291666666676|\n",
            "|2025|    1|14.406673209028435|\n",
            "+----+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# skip sea as runs slow\n",
        "\n",
        "import sys\n",
        "\n",
        "seago=False\n",
        "\n",
        "if seago==False:\n",
        "  sys.exit(\"No sea calc today.\")\n"
      ],
      "metadata": {
        "id": "D2nBVAg2M1oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c7d77062-be1c-46d1-bfc2-757eb1320d94"
      },
      "id": "D2nBVAg2M1oL",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "No sea calc today.",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m No sea calc today.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sea"
      ],
      "metadata": {
        "id": "IbdsQCKaFl7n"
      },
      "id": "IbdsQCKaFl7n"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "ga=[]\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "       if filename.endswith('waves.json'):\n",
        "        # Read the CSV file into a DataFrame\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        fo = open(filepath)\n",
        "        fs=fo.read()\n",
        "        jf=json.loads(fs)\n",
        "        for s in jf['hours']:\n",
        "          f=[s['time'], s['waterTemperature']['noaa'],s['waveHeight']['noaa'],s['swellHeight']['noaa'],s['windWaveHeight']['noaa']]\n",
        "          g=pd.DataFrame(f).T\n",
        "          g.columns=['time','temp','height', 'swell', 'wind']\n",
        "          g['time'] = pd.to_datetime(g['time'])\n",
        "          g.set_index(\"time\", inplace=True)\n",
        "          ga.append(g)\n",
        "        fo.close()\n",
        "\n",
        "\n",
        "\n",
        "# Combine all DataFrames into one\n",
        "sdf = pd.concat(ga, ignore_index=False)\n",
        "\n",
        "# Drop duplicate rows\n",
        "sdfc = sdf.drop_duplicates()\n",
        "\n"
      ],
      "metadata": {
        "id": "eHe-M5ycFnqJ"
      },
      "id": "eHe-M5ycFnqJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f"
      ],
      "metadata": {
        "id": "qfzpFMVO9w6o"
      },
      "id": "qfzpFMVO9w6o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s.keys()"
      ],
      "metadata": {
        "id": "UFHYPGOX85E6"
      },
      "id": "UFHYPGOX85E6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdfc = sdfc.reset_index()\n",
        "\n",
        "spark_df = spark.createDataFrame(sdfc)"
      ],
      "metadata": {
        "id": "BXQUPgQIKiKj"
      },
      "id": "BXQUPgQIKiKj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.createOrReplaceTempView(\"sea\")"
      ],
      "metadata": {
        "id": "-qJ_BlzsKix4"
      },
      "id": "-qJ_BlzsKix4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT\n",
        "    round(MAX(temp),2) AS max_temp,\n",
        "    round(MIN(temp),2) AS min_temp,\n",
        "    round(AVG(temp),2) AS ave_temp,\n",
        "    YEAR(time) AS year,\n",
        "    MONTH(time) AS month\n",
        "FROM sea\n",
        "WHERE HOUR(time) = 12\n",
        "GROUP BY YEAR(time), MONTH(time)\n",
        "ORDER BY max_temp desc\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "xpcEGPAsKcKF"
      },
      "id": "xpcEGPAsKcKF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT\n",
        "    round(MAX(height),2) AS max_height,\n",
        "    round(AVG(height),2) AS avg_height,\n",
        "    YEAR(time) AS year,\n",
        "    MONTH(time) AS month\n",
        "FROM sea\n",
        "WHERE HOUR(time) = 12\n",
        "GROUP BY YEAR(time), MONTH(time)\n",
        "ORDER BY avg_height desc\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "GPDuYWgY9f_0"
      },
      "id": "GPDuYWgY9f_0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT * from sea\n",
        "order by YEAR(time) desc, MONTH(time) desc\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "RYTjdxiYIWkY"
      },
      "id": "RYTjdxiYIWkY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}