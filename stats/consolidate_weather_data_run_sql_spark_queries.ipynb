{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/werowe/HypatiaAcademy/blob/master/stats/consolidate_weather_data_run_sql_spark_queries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "66d4c911-ce31-48b6-8481-cfb6c16a8d7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66d4c911-ce31-48b6-8481-cfb6c16a8d7f",
        "outputId": "30dd3dca-b6dc-487c-c780-4be300a8186b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "93195920-9c74-4605-a6ba-b5c3b67f41af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93195920-9c74-4605-a6ba-b5c3b67f41af",
        "outputId": "a8dab1eb-ef15-4b0e-e915-ac9ae243eb8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined DataFrame shape: (18119, 24)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the directory containing the CSV files\n",
        "directory = 'drive/MyDrive/weather'\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Loop through files in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    # Check if the file starts with 'paphos2024' and ends with '.csv'\n",
        "    if filename.startswith('paphos20') and filename.endswith('.csv'):\n",
        "        # Read the CSV file into a DataFrame\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        df = pd.read_csv(filepath)\n",
        "        dataframes.append(df)\n",
        "\n",
        "# Combine all DataFrames into one\n",
        "df_combined = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Drop duplicate rows\n",
        "df_combined = df_combined.drop_duplicates()\n",
        "\n",
        "# Save the combined DataFrame to a new CSV file (optional)\n",
        "df_combined.to_csv('combined_weather.csv', index=False)\n",
        "\n",
        "# Print a summary of the combined DataFrame\n",
        "print(f\"Combined DataFrame shape: {df_combined.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d274ac16-319c-452b-908f-1e4d16615dff",
      "metadata": {
        "id": "d274ac16-319c-452b-908f-1e4d16615dff"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"weather\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\n",
        "    \"combined_weather.csv\",\n",
        "    header=True,        # Use the first row as column names\n",
        "    inferSchema=True,   # Automatically infer data types\n",
        "    sep=\",\",            # Specify delimiter (default is ',')\n",
        "    encoding=\"UTF-8\"    # Handle encoding\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "IupJCWCHKOsi",
        "outputId": "1e186a63-876f-4f0c-aaa5-03cd62a60bad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IupJCWCHKOsi",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['name',\n",
              " 'datetime',\n",
              " 'temp',\n",
              " 'feelslike',\n",
              " 'dew',\n",
              " 'humidity',\n",
              " 'precip',\n",
              " 'precipprob',\n",
              " 'preciptype',\n",
              " 'snow',\n",
              " 'snowdepth',\n",
              " 'windgust',\n",
              " 'windspeed',\n",
              " 'winddir',\n",
              " 'sealevelpressure',\n",
              " 'cloudcover',\n",
              " 'visibility',\n",
              " 'solarradiation',\n",
              " 'solarenergy',\n",
              " 'uvindex',\n",
              " 'severerisk',\n",
              " 'conditions',\n",
              " 'icon',\n",
              " 'stations']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"weather\")"
      ],
      "metadata": {
        "id": "8SUAdh7AKQv7"
      },
      "id": "8SUAdh7AKQv7",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sql = '''\n",
        "SELECT round(SUM(precip)) AS total_precip, YEAR(datetime) AS year, MONTH(datetime) AS month\n",
        "FROM weather\n",
        "GROUP BY YEAR(datetime), MONTH(datetime)\n",
        "ORDER BY year, month\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dXKQSRLKVhe",
        "outputId": "6671f856-0c81-4de9-ba95-6836b1613dd2"
      },
      "id": "8dXKQSRLKVhe",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----+-----+\n",
            "|total_precip|year|month|\n",
            "+------------+----+-----+\n",
            "|        69.0|2024|    1|\n",
            "|        35.0|2024|    2|\n",
            "|         9.0|2024|    3|\n",
            "|         0.0|2024|    7|\n",
            "|         0.0|2024|    8|\n",
            "|         2.0|2024|    9|\n",
            "|         2.0|2024|   10|\n",
            "|       166.0|2024|   11|\n",
            "|       487.0|2024|   12|\n",
            "|        64.0|2025|    1|\n",
            "|       108.0|2025|    2|\n",
            "|        40.0|2025|    3|\n",
            "+------------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT round(avg(temp),2) AS temp, YEAR(datetime) AS year, MONTH(datetime) AS month\n",
        "FROM weather\n",
        "GROUP BY YEAR(datetime), MONTH(datetime)\n",
        "ORDER BY year, month\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "J-BfRSsAtLLi",
        "outputId": "7822ec98-f746-4303-c8d6-a105b6769b77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J-BfRSsAtLLi",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+-----+\n",
            "| temp|year|month|\n",
            "+-----+----+-----+\n",
            "|14.35|2024|    1|\n",
            "|14.39|2024|    2|\n",
            "|16.02|2024|    3|\n",
            "|29.12|2024|    7|\n",
            "|28.42|2024|    8|\n",
            "|26.56|2024|    9|\n",
            "|22.68|2024|   10|\n",
            "|18.29|2024|   11|\n",
            "|15.07|2024|   12|\n",
            "|14.31|2025|    1|\n",
            "|11.74|2025|    2|\n",
            "|16.41|2025|    3|\n",
            "+-----+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT avg(temp) AS temp, YEAR(datetime) AS year\n",
        "FROM weather\n",
        "GROUP BY YEAR(datetime)\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "bJKTvVCMtt0k",
        "outputId": "30f0717a-8352-4df6-95a5-970d51020608",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bJKTvVCMtt0k",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----+\n",
            "|             temp|year|\n",
            "+-----------------+----+\n",
            "|14.05378872120734|2025|\n",
            "|21.03340663058174|2024|\n",
            "+-----------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT YEAR(datetime) AS year, MONTH(datetime) AS month, AVG(temp) AS avg_temp\n",
        "FROM weather\n",
        "WHERE YEAR(datetime) IN (2025, 2024) AND MONTH(datetime) = 1\n",
        "GROUP BY YEAR(datetime), MONTH(datetime);\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "UBWbrQiJuYOX",
        "outputId": "31ccda62-deb8-46e0-e9d4-df4e37f83155",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UBWbrQiJuYOX",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+------------------+\n",
            "|year|month|          avg_temp|\n",
            "+----+-----+------------------+\n",
            "|2024|    1|14.354924242424257|\n",
            "|2025|    1|14.306578947368354|\n",
            "+----+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# skip sea as runs slow\n",
        "\n",
        "import sys\n",
        "\n",
        "seago=False\n",
        "\n",
        "if seago==False:\n",
        "  print(\"🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊 not calculating waves this time🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊\")\n",
        "  sys.exit(\"\\nNo sea calc today.\")\n"
      ],
      "metadata": {
        "id": "D2nBVAg2M1oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "dd1378aa-3773-4cda-c8bd-9a482c68487c"
      },
      "id": "D2nBVAg2M1oL",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊 not calculating waves this time🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊🌊\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "\nNo sea calc today.",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m \nNo sea calc today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sea"
      ],
      "metadata": {
        "id": "IbdsQCKaFl7n"
      },
      "id": "IbdsQCKaFl7n"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "ga=[]\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "       if filename.endswith('waves.json'):\n",
        "        # Read the CSV file into a DataFrame\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        fo = open(filepath)\n",
        "        fs=fo.read()\n",
        "        jf=json.loads(fs)\n",
        "        for s in jf['hours']:\n",
        "          f=[s['time'], s['waterTemperature']['noaa'],s['waveHeight']['noaa'],s['swellHeight']['noaa'],s['windWaveHeight']['noaa']]\n",
        "          g=pd.DataFrame(f).T\n",
        "          g.columns=['time','temp','height', 'swell', 'wind']\n",
        "          g['time'] = pd.to_datetime(g['time'])\n",
        "          g.set_index(\"time\", inplace=True)\n",
        "          ga.append(g)\n",
        "        fo.close()\n",
        "\n",
        "\n",
        "\n",
        "# Combine all DataFrames into one\n",
        "sdf = pd.concat(ga, ignore_index=False)\n",
        "\n",
        "# Drop duplicate rows\n",
        "sdfc = sdf.drop_duplicates()\n",
        "\n"
      ],
      "metadata": {
        "id": "eHe-M5ycFnqJ"
      },
      "id": "eHe-M5ycFnqJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f"
      ],
      "metadata": {
        "id": "qfzpFMVO9w6o"
      },
      "id": "qfzpFMVO9w6o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s.keys()"
      ],
      "metadata": {
        "id": "UFHYPGOX85E6"
      },
      "id": "UFHYPGOX85E6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdfc = sdfc.reset_index()\n",
        "\n",
        "spark_df = spark.createDataFrame(sdfc)"
      ],
      "metadata": {
        "id": "BXQUPgQIKiKj"
      },
      "id": "BXQUPgQIKiKj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.createOrReplaceTempView(\"sea\")"
      ],
      "metadata": {
        "id": "-qJ_BlzsKix4"
      },
      "id": "-qJ_BlzsKix4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT\n",
        "    round(MAX(temp),2) AS max_temp,\n",
        "    round(MIN(temp),2) AS min_temp,\n",
        "    round(AVG(temp),2) AS ave_temp,\n",
        "    YEAR(time) AS year,\n",
        "    MONTH(time) AS month\n",
        "FROM sea\n",
        "WHERE HOUR(time) = 12\n",
        "GROUP BY YEAR(time), MONTH(time)\n",
        "ORDER BY max_temp desc\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "xpcEGPAsKcKF"
      },
      "id": "xpcEGPAsKcKF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT\n",
        "    round(MAX(height),2) AS max_height,\n",
        "    round(AVG(height),2) AS avg_height,\n",
        "    YEAR(time) AS year,\n",
        "    MONTH(time) AS month\n",
        "FROM sea\n",
        "WHERE HOUR(time) = 12\n",
        "GROUP BY YEAR(time), MONTH(time)\n",
        "ORDER BY avg_height desc\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "GPDuYWgY9f_0"
      },
      "id": "GPDuYWgY9f_0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "SELECT * from sea\n",
        "order by YEAR(time) desc, MONTH(time) desc\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "result = spark.sql(sql)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "RYTjdxiYIWkY"
      },
      "id": "RYTjdxiYIWkY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}